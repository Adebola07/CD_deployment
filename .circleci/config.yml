version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  welcome: circleci/welcome-orb@0.4.1
  aws-cli: circleci/aws-cli@2.0.3

commands:
  # Exercise: Reusable Job Code
  print_pipeline_id:
    parameters:
      id: 
        type: string
    steps:
      - run: echo << parameters.id >>

  # Exercise - Rollback
  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}
# Define the jobs we want to run for this project
jobs:
  myjob1:  # Choose any name, such as `build`
      # The primary container, where your job's commands will run
      docker:
        - image: alpine:3.15
      steps:
        - checkout # check out the code in the project directory
        - run: echo "hello world on this day" # run the `echo` command
# Sequential workflow
#  create_infrastructure: 
#     docker:
#       - image: amazon/aws-cli
#     steps:
#       - checkout
#       - run:
#            name: Create Cloudformation Stack
#            command: |
#              aws cloudformation deploy \
#              --template-file template.yml \
#              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
#              --region us-east-1
#       - run: return 1
#       - destroy_environment       

  # Exercise: Config and Deployment
#  configure_infrastructure: 
#    docker:
#      - image: python:3.7-alpine3.11
#    steps:
#      - checkout
#      - run: apk add --update openssh-client git
#      - add_ssh_keys:
#            # You can get this ID in the section where you registered the SSH Key
#            fingerprints: ["07:73:6e:5c:54:98:35:64:3e:04:fc:2d:ce:2f:53:c1"] 
#      - run:
#          name: Install Ansible
#          command: |
#               apk add --update ansible
#      - run:
#          name: Run Playbook and Configure server
#          command: |
#              ansible-playbook -i inventory test.yml
#  Smoke_Test:
#      docker:
#        - image: alpine:latest
#      steps:
#        - run: apk add --update curl
#        - run:
#            name: smoke_test
#            command: |
#                URL = "https://blog.udacity.com/"
#                # Test if the website exists
#                if curl -s --head ${URL}
#                then
#                  return 0
#                else
#                  return 1
#                fi
#        - destroy_environment 


        # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
    # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
#  create_and_deploy_front_end:
#      docker:
#      - image: amazon/aws-cli
#      steps:
#      - checkout
#      - run:
#          name: Execute bucket.yml - Create Cloudformation Stack
#          command: |
#            aws cloudformation deploy \
#            --template-file bucket.yml \
#            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
#            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
#      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
#      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete
#
  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
#  get_last_deployment_id:
#    docker:
#      - image: amazon/aws-cli
#    steps:
#      - checkout
#      - run: yum install -y tar gzip
#      - run:
#          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
#          command: |
#            aws cloudformation \
#            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
#            --no-paginate --output text > ~/textfile.txt
#      - persist_to_workspace:
#          root: ~/
#          paths: 
#            - textfile.txt 

    # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
#  promote_to_production:
#    docker:
#      - image: amazon/aws-cli
#    steps:
#      - checkout
#      - run:
#          name: Execute cloudfront.yml
#          command: |
#            aws cloudformation deploy \
#            --template-file cloudfront.yml \
#            --stack-name production-distro \
#            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}" 

      # Destroy the previous production version's S3 bucket and CloudFormation stack. 
#  clean_up_old_front_end:
#    docker:
#      - image: amazon/aws-cli
#    steps:
#      - checkout
#      - run: yum install -y tar gzip
#      - attach_workspace:
#          at: ~/
#      - run:
#          name: Destroy the previous S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
#          command: |
#            export OldBucketID=$(cat ~/textfile.txt)
#            aws s3 rm "s3://${OldBucketID}" --recursive        
workflows:
 # Name the workflow
  myWorkflow:
    jobs:
      - myjob1
      #- create_infrastructure
      #- configure_infrastructure
      #- Smoke_Test:
      #- create_and_deploy_front_end
      #- promote_to_production:
      #      requires: 
      #        - create_and_deploy_front_end
      #- get_last_deployment_id
      #- clean_up_old_front_end:
      #      requires:
      #        - get_last_deployment_id
      #        - promote_to_production
